{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc8b72f-1858-4f21-9b51-f6773963615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b16c075-5c65-4c0e-b68e-c43643cf9e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID        imgfile\n",
      "0      4470801  d015s0007.jpg\n",
      "1      4470801  d015s0103.jpg\n",
      "2      4470801  d015s0023.jpg\n",
      "3      4470801  d015s0065.jpg\n",
      "4      4470801  d015s0118.jpg\n",
      "5      4470801  d015s0017.jpg\n",
      "6      4470801  d015s0124.jpg\n",
      "7      4470801  d015s0049.jpg\n",
      "8      4470801  d015s0052.jpg\n",
      "9      4470801  d015s0080.jpg\n",
      "10     4470801  d015s0073.jpg\n",
      "11     4470801  d015s0011.jpg\n",
      "12     4470801  d015s0055.jpg\n",
      "13     4470801  d015s0081.jpg\n",
      "14     4470801  d015s0108.jpg\n",
      "15     4470801  d015s0013.jpg\n",
      "16     4470801  d015s0056.jpg\n",
      "17     4470801  d015s0020.jpg\n",
      "18     4470801  d015s0106.jpg\n",
      "19     4470801  d015s0012.jpg\n",
      "20     4470801  d015s0072.jpg\n",
      "21     4470801  d015s0006.jpg\n",
      "22     4470801  d015s0116.jpg\n",
      "23     4470801  d015s0061.jpg\n",
      "24     4470801  d015s0123.jpg\n",
      "25     4470801  d015s0120.jpg\n",
      "26     4470801  d015s0067.jpg\n",
      "27     4470801  d015s0019.jpg\n",
      "28     4470801  d015s0038.jpg\n",
      "29     4470801  d015s0090.jpg\n",
      "...        ...            ...\n",
      "62751  1037319  d060s0056.jpg\n",
      "62752  1037319  d060s0270.jpg\n",
      "62753  1037319  d060s0250.jpg\n",
      "62754  1037319  d060s0073.jpg\n",
      "62755  1037319  d060s0155.jpg\n",
      "62756  1037319  d060s0035.jpg\n",
      "62757  1037319  d060s0076.jpg\n",
      "62758  1037319  d060s0018.jpg\n",
      "62759  1037319  d060s0125.jpg\n",
      "62760  1037319  d060s0033.jpg\n",
      "62761  1037319  d060s0108.jpg\n",
      "62762  1037319  d060s0178.jpg\n",
      "62763  1037319  d060s0170.jpg\n",
      "62764  1037319  d060s0299.jpg\n",
      "62765  1037319  d060s0070.jpg\n",
      "62766  1037319  d060s0012.jpg\n",
      "62767  1037319  d060s0085.jpg\n",
      "62768  1037319  d060s0215.jpg\n",
      "62769  1037319  d060s0092.jpg\n",
      "62770  1037319  d060s0227.jpg\n",
      "62771  1037319  d060s0127.jpg\n",
      "62772  1037319  d060s0242.jpg\n",
      "62773  1037319  d060s0140.jpg\n",
      "62774  1037319  d060s0007.jpg\n",
      "62775  1037319  d060s0252.jpg\n",
      "62776  1037319  d060s0305.jpg\n",
      "62777  1037319  d060s0292.jpg\n",
      "62778  1037319  d060s0013.jpg\n",
      "62779  1037319  d060s0269.jpg\n",
      "62780  1037319  d060s0282.jpg\n",
      "\n",
      "[62781 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "IDToIndex = {}\n",
    "indexToID = {}\n",
    "IDtonum = {}\n",
    "IDtoimg={}\n",
    "\n",
    "index = -3\n",
    "for dirname, _, filenames in os.walk('./insect/database'):\n",
    "    if(index > -1):\n",
    "        specie = dirname.rsplit('/', 1)[1] \n",
    "        IDToIndex[specie] = index\n",
    "        indexToID[index] = specie\n",
    "        IDtonum[specie]=len(filenames)\n",
    "        IDtoimg[specie]=filenames\n",
    "    index = index + 1\n",
    "#Creating our first dataframe of Insect IDs and picture file names\n",
    "predf = []\n",
    "for specie, imgs in IDtoimg.items():\n",
    "    for img in imgs:\n",
    "        predf.append({'ID': specie, 'imgfile': img})\n",
    "df1 = pd.DataFrame(predf)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da834764-a6b2-4694-8174-4eb2326fa319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "idToNum_df = pd.DataFrame(IDtonum.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e610ad-1cdf-4b3a-a08a-bc1c8a14d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9364935, 888], [1035931, 861], [7508714, 818], [4475140, 719], [1036216, 686], [5755079, 651], [4474169, 642], [1035185, 599], [1035195, 570], [1035864, 566]]\n",
      "       key  quantity\n",
      "0  9364935       888\n",
      "1  1035931       861\n",
      "2  7508714       818\n",
      "3  4475140       719\n",
      "4  1036216       686\n",
      "5  5755079       651\n",
      "6  4474169       642\n",
      "7  1035185       599\n",
      "8  1035195       570\n",
      "9  1035864       566\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "top10 = []\n",
    "for x in sorted(IDtonum, key=IDtonum.get, reverse=True):\n",
    "    if i < 10:\n",
    "        top10.append([int(x), IDtonum[x]])\n",
    "        i+=1\n",
    "print(top10)\n",
    "\n",
    "top10df = pd.DataFrame(top10, columns=['key', 'quantity'])\n",
    "print(top10df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c091185-7414-4fbc-a875-0f365edc95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'key': [1036216, 7508714, 1035931, 4475140, 1035864, 1035185, 4474169, 5755079, 1035195, 9364935],\n",
    "    'family': ['Carabidae'] * 10,\n",
    "    # 'genus': ['Nebria', 'Bembidion', 'Pterostichus', 'Pterostichus', 'Bembidion', 'Elaphrus', 'Ophonus', \n",
    "    #           'Pterostichus', 'Harpalus', 'Pterostichus', 'Bembidion', 'Amara', 'Calathus', 'Bembidion', \n",
    "    #           'Paranchus', 'Anchomenus', 'Agonum', 'Amara', 'Notiophilus', 'Acupalpus'],\n",
    "    # 'species': ['Nebria brevicollis', 'Bembidion lampros', 'Pterostichus nigrita', 'Pterostichus strenuus', \n",
    "    #             'Bembidion tetracolum', 'Elaphrus riparius', 'Ophonus rufibarbis', 'Pterostichus madidus', \n",
    "    #             'Harpalus serripes', 'Pterostichus diligens', 'Bembidion dentellum', 'Amara aenea', \n",
    "    #             'Calathus melanocephalus', 'Bembidion guttula', 'Paranchus albipes', 'Anchomenus dorsalis', \n",
    "    #             'Agonum fuliginosum', 'Amara familiaris', 'Notiophilus biguttatus', 'Acupalpus dubius']\n",
    "}\n",
    "species10 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16e14bde-f1a8-42d1-acb9-71d9d7584aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      family      key  quantity\n",
      "0  Carabidae  1036216       686\n",
      "1  Carabidae  7508714       818\n",
      "2  Carabidae  1035931       861\n",
      "3  Carabidae  4475140       719\n",
      "4  Carabidae  1035864       566\n",
      "5  Carabidae  1035185       599\n",
      "6  Carabidae  4474169       642\n",
      "7  Carabidae  5755079       651\n",
      "8  Carabidae  1035195       570\n",
      "9  Carabidae  9364935       888\n"
     ]
    }
   ],
   "source": [
    "species10_q = species10.merge(top10df, on='key', how='left')\n",
    "print(species10_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2448421e-7387-4b46-8e91-99c4fba268fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[686, 818, 861, 719, 566, 599, 642, 651, 570, 888]\n",
      "{1035195: 8, 4475140: 3, 9364935: 9, 1035185: 5, 7508714: 1, 5755079: 7, 1035864: 4, 1036216: 0, 4474169: 6, 1035931: 2}\n"
     ]
    }
   ],
   "source": [
    "num_per_spec = species10_q.quantity.tolist()\n",
    "print(num_per_spec)\n",
    "id_to_label = {}\n",
    "id_spec = species10_q.key.tolist()\n",
    "for idx, id_ in enumerate(id_spec):\n",
    "    id_to_label[id_] = idx\n",
    "print(id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0270afc1-3540-4c7c-93d8-da45cd72b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID        imgfile\n",
      "0     1036216  d068s0002.jpg\n",
      "1     1036216  d068s0502.jpg\n",
      "2     1036216  d068s0458.jpg\n",
      "3     1036216  d068s0145.jpg\n",
      "4     1036216  d068s0003.jpg\n",
      "5     1036216  d068s0609.jpg\n",
      "6     1036216  d068s0228.jpg\n",
      "7     1036216  d068s0414.jpg\n",
      "8     1036216  d068s0064.jpg\n",
      "9     1036216  d068s0604.jpg\n",
      "10    1036216  d068s0467.jpg\n",
      "11    1036216  d068s0565.jpg\n",
      "12    1036216  d068s0133.jpg\n",
      "13    1036216  d068s0175.jpg\n",
      "14    1036216  d068s0299.jpg\n",
      "15    1036216  d068s0132.jpg\n",
      "16    1036216  d068s0112.jpg\n",
      "17    1036216  d068s0533.jpg\n",
      "18    1036216  d068s0583.jpg\n",
      "19    1036216  d068s0333.jpg\n",
      "20    1036216  d068s0075.jpg\n",
      "21    1036216  d068s0078.jpg\n",
      "22    1036216  d068s0262.jpg\n",
      "23    1036216  d068s0503.jpg\n",
      "24    1036216  d068s0260.jpg\n",
      "25    1036216  d068s0014.jpg\n",
      "26    1036216  d068s0679.jpg\n",
      "27    1036216  d068s0085.jpg\n",
      "28    1036216  d068s0544.jpg\n",
      "29    1036216  d068s0452.jpg\n",
      "...       ...            ...\n",
      "6970  4474169  d140s0223.jpg\n",
      "6971  4474169  d141s0105.jpg\n",
      "6972  4474169  d140s0155.jpg\n",
      "6973  4474169  d141s0012.jpg\n",
      "6974  4474169  d140s0464.jpg\n",
      "6975  4474169  d140s0397.jpg\n",
      "6976  4474169  d140s0282.jpg\n",
      "6977  4474169  d141s0006.jpg\n",
      "6978  4474169  d140s0010.jpg\n",
      "6979  4474169  d140s0289.jpg\n",
      "6980  4474169  d141s0010.jpg\n",
      "6981  4474169  d141s0017.jpg\n",
      "6982  4474169  d140s0339.jpg\n",
      "6983  4474169  d140s0185.jpg\n",
      "6984  4474169  d141s0115.jpg\n",
      "6985  4474169  d140s0523.jpg\n",
      "6986  4474169  d140s0248.jpg\n",
      "6987  4474169  d140s0365.jpg\n",
      "6988  4474169  d141s0110.jpg\n",
      "6989  4474169  d141s0063.jpg\n",
      "6990  4474169  d141s0061.jpg\n",
      "6991  4474169  d141s0049.jpg\n",
      "6992  4474169  d140s0529.jpg\n",
      "6993  4474169  d141s0058.jpg\n",
      "6994  4474169  d140s0387.jpg\n",
      "6995  4474169  d140s0247.jpg\n",
      "6996  4474169  d140s0375.jpg\n",
      "6997  4474169  d140s0092.jpg\n",
      "6998  4474169  d140s0198.jpg\n",
      "6999  4474169  d141s0047.jpg\n",
      "\n",
      "[7000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "top10_str = []\n",
    "for x in top10df['key']:\n",
    "    top10_str.append(str(x))\n",
    "    \n",
    "df2 = df1[df1['ID'].isin(top10_str)].reset_index(drop=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3126ce-fac9-426b-9afd-3d7fc7d05fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf9a1ce2-0ffc-47fa-8c22-0e4311b89ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./insect/database/\"\n",
    "classes = os.listdir(data_dir)\n",
    "class_to_index = {cls: i for i, cls in enumerate(classes)}\n",
    "index_to_class = {i: cls for i, cls in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35c0bc33-2516-4ffd-b219-006cde402c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 28, 28, 1)\n",
      "(7000, 10)\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "\n",
    "for cls in classes:\n",
    "    if cls in top10_str:  # 상위 20종만 처리, 종의 수에 따라 조정 가능\n",
    "        cls_dir = os.path.join(data_dir, cls)\n",
    "        for img_file in os.listdir(cls_dir):\n",
    "            img_path = os.path.join(cls_dir, img_file)\n",
    "            \n",
    "            # 이미지를 흑백 모드로 읽음\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # 이미지를 28x28 크기로 리사이즈\n",
    "            img = cv2.resize(img, (img_height, img_width))\n",
    "            img = img / 255.0\n",
    "            images.append(img)\n",
    "            label = np.zeros(10)\n",
    "            label[id_to_label[int(cls)]] = 1\n",
    "            labels.append(label)            \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727ff13d-240c-49cf-b874-61b4c50df462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f899f8dc-3a30-4abe-8c30-53c5cfaedfe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-93-b6968a96bc9a>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-93-b6968a96bc9a>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    for i, value\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# unique = list(set(y_train))\n",
    "# value_to_index = {value:idx for idx, value in enumerate(unique)}\n",
    "# one_hot_encoded = np.zeros((len(y_train), len(unique_values)))\n",
    "# for i, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68d128ae-5a0f-4ff3-b6ad-4fa011c42685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a88825-f130-48db-9833-491b2d398ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Metric to monitor\n",
    "    patience=10,         # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,           # To log the number of epochs after which training was stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the minimum validation loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29bbb07d-a93f-432c-9344-d40bdde87482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'bug_model1.keras',        # Path where to save the model\n",
    "    monitor='val_accuracy', # Metric to monitor\n",
    "    save_best_only=True,    # Only save a model if `val_accuracy` has improved\n",
    "    verbose=1               # Log when a new best model is saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8d3bc05-ec2c-4b99-9fcc-fff0375fa8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 9, 9, 16)          6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 15,130\n",
      "Trainable params: 15,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10 # change based on species num\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Conv layer 1\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(img_height, img_width, 1), name=\"conv1\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Conv layer 2\n",
    "model.add(Conv2D(16, (5, 5), activation='relu', name=\"conv2\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten and Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu', name=\"fc1\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax', name = \"fc2\"))\n",
    "\n",
    "# Compile\n",
    "model.compile(Adam(learning_rate=0.005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 모델 구조 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "595bdb6a-2bac-46ca-a914-01fd089df7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5600 samples, validate on 1400 samples\n",
      "Epoch 1/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 2.1393 - acc: 0.1819WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 6s 1ms/sample - loss: 2.1377 - acc: 0.1825 - val_loss: 2.0228 - val_acc: 0.2136\n",
      "Epoch 2/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.9130 - acc: 0.2917WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 901us/sample - loss: 1.9119 - acc: 0.2918 - val_loss: 1.8661 - val_acc: 0.3236\n",
      "Epoch 3/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.7566 - acc: 0.3554WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 854us/sample - loss: 1.7568 - acc: 0.3557 - val_loss: 1.7140 - val_acc: 0.3750\n",
      "Epoch 4/50\n",
      "5408/5600 [===========================>..] - ETA: 0s - loss: 1.6512 - acc: 0.4027WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 7s 1ms/sample - loss: 1.6496 - acc: 0.4029 - val_loss: 1.6672 - val_acc: 0.3664\n",
      "Epoch 5/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.5943 - acc: 0.4187- ETA: 2s - lWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 724us/sample - loss: 1.5958 - acc: 0.4182 - val_loss: 1.6001 - val_acc: 0.4257\n",
      "Epoch 6/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.5243 - acc: 0.4511WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 680us/sample - loss: 1.5242 - acc: 0.4505 - val_loss: 1.5941 - val_acc: 0.4186\n",
      "Epoch 7/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.4872 - acc: 0.4585WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 930us/sample - loss: 1.4869 - acc: 0.4586 - val_loss: 1.5483 - val_acc: 0.4214\n",
      "Epoch 8/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.4472 - acc: 0.4745WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 891us/sample - loss: 1.4458 - acc: 0.4750 - val_loss: 1.4868 - val_acc: 0.4371\n",
      "Epoch 9/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 1.3908 - acc: 0.4945WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 805us/sample - loss: 1.3912 - acc: 0.4945 - val_loss: 1.4755 - val_acc: 0.4493\n",
      "Epoch 10/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.3717 - acc: 0.4986WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 844us/sample - loss: 1.3700 - acc: 0.4996 - val_loss: 1.4637 - val_acc: 0.4629\n",
      "Epoch 11/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 1.3385 - acc: 0.5094- ETA:WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 857us/sample - loss: 1.3386 - acc: 0.5091 - val_loss: 1.4902 - val_acc: 0.4429\n",
      "Epoch 12/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 1.3194 - acc: 0.5174WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 755us/sample - loss: 1.3200 - acc: 0.5179 - val_loss: 1.4064 - val_acc: 0.4714\n",
      "Epoch 13/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 1.2912 - acc: 0.5267- ETA: 1s - loWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 835us/sample - loss: 1.2899 - acc: 0.5275 - val_loss: 1.3658 - val_acc: 0.5014\n",
      "Epoch 14/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.2656 - acc: 0.5415WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 825us/sample - loss: 1.2645 - acc: 0.5423 - val_loss: 1.3923 - val_acc: 0.4879\n",
      "Epoch 15/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.2461 - acc: 0.5478WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 810us/sample - loss: 1.2461 - acc: 0.5477 - val_loss: 1.6746 - val_acc: 0.3957\n",
      "Epoch 16/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.2300 - acc: 0.5493WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 778us/sample - loss: 1.2283 - acc: 0.5496 - val_loss: 1.3001 - val_acc: 0.5179\n",
      "Epoch 17/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.1978 - acc: 0.5636WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 712us/sample - loss: 1.1978 - acc: 0.5634 - val_loss: 1.3212 - val_acc: 0.5164\n",
      "Epoch 18/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.1862 - acc: 0.5607WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 6s 1ms/sample - loss: 1.1869 - acc: 0.5607 - val_loss: 1.3073 - val_acc: 0.5100\n",
      "Epoch 19/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.1821 - acc: 0.5627WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 825us/sample - loss: 1.1811 - acc: 0.5632 - val_loss: 1.3193 - val_acc: 0.5186\n",
      "Epoch 20/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.1704 - acc: 0.5723WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 723us/sample - loss: 1.1688 - acc: 0.5730 - val_loss: 1.2707 - val_acc: 0.5350\n",
      "Epoch 21/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.1351 - acc: 0.5878WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 909us/sample - loss: 1.1357 - acc: 0.5879 - val_loss: 1.3256 - val_acc: 0.5114\n",
      "Epoch 22/50\n",
      "5408/5600 [===========================>..] - ETA: 0s - loss: 1.1341 - acc: 0.5843- ETA: 1s - loss: 1.1340 - WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 6s 995us/sample - loss: 1.1331 - acc: 0.5864 - val_loss: 1.3144 - val_acc: 0.5250\n",
      "Epoch 23/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.1135 - acc: 0.5900WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 758us/sample - loss: 1.1140 - acc: 0.5904 - val_loss: 1.2990 - val_acc: 0.5193\n",
      "Epoch 24/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.0934 - acc: 0.5961WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 823us/sample - loss: 1.0961 - acc: 0.5948 - val_loss: 1.2446 - val_acc: 0.5443\n",
      "Epoch 25/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.0957 - acc: 0.6035WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 885us/sample - loss: 1.0949 - acc: 0.6041 - val_loss: 1.3066 - val_acc: 0.5229\n",
      "Epoch 26/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.0778 - acc: 0.6083WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 737us/sample - loss: 1.0775 - acc: 0.6080 - val_loss: 1.2322 - val_acc: 0.5436\n",
      "Epoch 27/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.0765 - acc: 0.6057WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 861us/sample - loss: 1.0760 - acc: 0.6059 - val_loss: 1.2325 - val_acc: 0.5486\n",
      "Epoch 28/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.0740 - acc: 0.6098WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 767us/sample - loss: 1.0750 - acc: 0.6091 - val_loss: 1.2403 - val_acc: 0.5507\n",
      "Epoch 29/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.0588 - acc: 0.6104WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 953us/sample - loss: 1.0601 - acc: 0.6100 - val_loss: 1.2796 - val_acc: 0.5314\n",
      "Epoch 30/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.0489 - acc: 0.6212- ETA: 1s - loss: 1.0311  - ETA: 0s - loss: 1.0477 - acc: 0.62WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 769us/sample - loss: 1.0485 - acc: 0.6212 - val_loss: 1.2352 - val_acc: 0.5514\n",
      "Epoch 31/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 1.0461 - acc: 0.6108WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 3s 612us/sample - loss: 1.0438 - acc: 0.6112 - val_loss: 1.2212 - val_acc: 0.5614\n",
      "Epoch 32/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 1.0250 - acc: 0.6226WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 703us/sample - loss: 1.0245 - acc: 0.6225 - val_loss: 1.2253 - val_acc: 0.5579\n",
      "Epoch 33/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.0219 - acc: 0.6189WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 790us/sample - loss: 1.0234 - acc: 0.6191 - val_loss: 1.1967 - val_acc: 0.5707\n",
      "Epoch 34/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 1.0015 - acc: 0.6326WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 765us/sample - loss: 1.0025 - acc: 0.6316 - val_loss: 1.1946 - val_acc: 0.5686\n",
      "Epoch 35/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.0289 - acc: 0.6257WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 838us/sample - loss: 1.0287 - acc: 0.6259 - val_loss: 1.1984 - val_acc: 0.5771\n",
      "Epoch 36/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 1.0038 - acc: 0.6326WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 765us/sample - loss: 1.0059 - acc: 0.6314 - val_loss: 1.2093 - val_acc: 0.5664\n",
      "Epoch 37/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 1.0015 - acc: 0.6356WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 753us/sample - loss: 1.0000 - acc: 0.6359 - val_loss: 1.2079 - val_acc: 0.5771\n",
      "Epoch 38/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 0.9928 - acc: 0.6339WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 855us/sample - loss: 0.9932 - acc: 0.6338 - val_loss: 1.1724 - val_acc: 0.5879\n",
      "Epoch 39/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 0.9826 - acc: 0.6385WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 6s 1ms/sample - loss: 0.9829 - acc: 0.6380 - val_loss: 1.2410 - val_acc: 0.5586\n",
      "Epoch 40/50\n",
      "5472/5600 [============================>.] - ETA: 0s - loss: 0.9803 - acc: 0.6446WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 7s 1ms/sample - loss: 0.9789 - acc: 0.6464 - val_loss: 1.2276 - val_acc: 0.5686\n",
      "Epoch 41/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 0.9827 - acc: 0.6354WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 832us/sample - loss: 0.9846 - acc: 0.6350 - val_loss: 1.2112 - val_acc: 0.5743\n",
      "Epoch 42/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 0.9758 - acc: 0.6394WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 793us/sample - loss: 0.9747 - acc: 0.6398 - val_loss: 1.2477 - val_acc: 0.5700\n",
      "Epoch 43/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 0.9693 - acc: 0.6430WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 946us/sample - loss: 0.9695 - acc: 0.6430 - val_loss: 1.1786 - val_acc: 0.5964\n",
      "Epoch 44/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 0.9586 - acc: 0.6465WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 761us/sample - loss: 0.9587 - acc: 0.6468 - val_loss: 1.1750 - val_acc: 0.5943\n",
      "Epoch 45/50\n",
      "5472/5600 [============================>.] - ETA: 0s - loss: 0.9637 - acc: 0.6489WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 5s 890us/sample - loss: 0.9647 - acc: 0.6479 - val_loss: 1.3089 - val_acc: 0.5550\n",
      "Epoch 46/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 0.9637 - acc: 0.6426WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 767us/sample - loss: 0.9656 - acc: 0.6421 - val_loss: 1.2837 - val_acc: 0.5671\n",
      "Epoch 47/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 0.9470 - acc: 0.6561WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 6s 1ms/sample - loss: 0.9466 - acc: 0.6557 - val_loss: 1.1980 - val_acc: 0.5886\n",
      "Epoch 48/50\n",
      "5504/5600 [============================>.] - ETA: 0s - loss: 0.9382 - acc: 0.6579WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 6s 1ms/sample - loss: 0.9387 - acc: 0.6575 - val_loss: 1.2011 - val_acc: 0.5914\n",
      "Epoch 49/50\n",
      "5536/5600 [============================>.] - ETA: 0s - loss: 0.9298 - acc: 0.6577- ETA: 1s - loss: 0.9264 - aWARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 6s 1ms/sample - loss: 0.9313 - acc: 0.6571 - val_loss: 1.1817 - val_acc: 0.5807\n",
      "Epoch 50/50\n",
      "5568/5600 [============================>.] - ETA: 0s - loss: 0.9413 - acc: 0.6577WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: acc,loss,val_acc,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "5600/5600 [==============================] - 4s 675us/sample - loss: 0.9403 - acc: 0.6582 - val_loss: 1.2240 - val_acc: 0.5871\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, model_checkpoint]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "570057c3-3e78-4bfe-b0ac-2e4f638834dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fdb2bca-abc5-4c6d-9312-bbf3791672a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f738745-087b-4326-bb36-49fc2bd300bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights and biases function\n",
    "def save_layer_params(layer_name, layer):\n",
    "    layer_name = './params/'+layer_name\n",
    "    # 가중치와 편향을 가져옴\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(weights.shape)\n",
    "    print(layer_name)\n",
    "    # 가중치 저장\n",
    "    with open(layer_name + '_w.param', 'wb') as f_w:\n",
    "        pickle.dump(weights, f_w)\n",
    "    \n",
    "    # 편향 저장\n",
    "    with open(layer_name + '_b.param', 'wb') as f_b:\n",
    "        pickle.dump(biases, f_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31b057bf-e663-463d-a6e4-7de081fb6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "(3, 3, 1, 16)\n",
      "./params/conv1\n",
      "hello\n",
      "(5, 5, 16, 16)\n",
      "./params/conv2\n",
      "hello\n",
      "(256, 32)\n",
      "./params/fc1\n",
      "hello\n",
      "(32, 10)\n",
      "./params/fc2\n"
     ]
    }
   ],
   "source": [
    "# 모델의 각 레이어별로 가중치와 편향 저장\n",
    "for layer in model.layers:\n",
    "    if len(layer.get_weights()) > 0:  # 가중치가 있는 레이어만 저장\n",
    "        print(\"hello\")\n",
    "        save_layer_params(layer.name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec4dbacf-e606-4cb2-8bfe-a53641787c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_first_data(df, save_path='./input.param'):\n",
    "    first_data = df.iloc[0]\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(first_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b716dc21-aa01-4dde-b3d6-6b3cba18ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train[0].reshape(28, 28)\n",
    "with open('./input.param', 'wb') as f: \n",
    "    pickle.dump(temp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23b7f405-ce72-456c-aa05-2827d8eac7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19d21fa9-e1a4-482c-97a4-18e30cb9a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1648081e-04, 2.5093153e-01, 1.5717106e-01, 1.5328967e-03,\n",
       "        1.0317753e-04, 2.4505269e-05, 1.4516088e-01, 4.4471222e-01,\n",
       "        7.1555536e-05, 7.5757678e-05]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[0].reshape(1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2aae61-5db5-4c94-a070-b81d38550de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27_tf115",
   "language": "python",
   "name": "py27_tf115"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
